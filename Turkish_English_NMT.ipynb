{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turkish/English NMT",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorkemozkaya/nmt-en-tr/blob/master/Turkish_English_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPNUeDW-r6Pc",
        "colab_type": "text"
      },
      "source": [
        "# Running the pre-trained NMT models in Python\n",
        "\n",
        "This notebook illustrates how one can load the pre-trained models and run it on new Turkish or English sentences for translation. It is mostly based on [this](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb) tensor2tensor notebook from the official [tensor2tensor](https://github.com/tensorflow/tensor2tensor) repository. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgDcx0z3-gVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --quiet tensorflow==1.14 tensor2tensor==1.13.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In7jXIJMnykD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Enable TF Eager execution\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "tfe = tf.contrib.eager\n",
        "tfe.enable_eager_execution() \n",
        "\n",
        "import numpy as np\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.data_generators import text_encoder\n",
        "\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "\n",
        "import textwrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs8aEqWMAkyy",
        "colab_type": "text"
      },
      "source": [
        "## Clone the repository and import the module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTiAyrKZ-nB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!test -d nmt-en-tr || git clone https://github.com/gorkemozkaya/nmt-en-tr.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFx0mlKk_BCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"nmt-en-tr\")\n",
        "import nmt_en_tr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXnvXaDuAW_q",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and loading the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDaatfgtAipi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -nc -q https://github.com/gorkemozkaya/nmt-en-tr/releases/download/pretrained_model/en2tr.zip\n",
        "!unzip -n -qq en2tr.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXf687ynA4wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = 'en2tr'\n",
        "\n",
        "data_dir = os.path.join(model_path, 'data')\n",
        "ckpt_dir = os.path.join(model_path, 'model')\n",
        "\n",
        "en2tr_problem = problems.problem(\"translate_en_tr\")\n",
        "encoders = en2tr_problem.feature_encoders(data_dir)\n",
        "\n",
        "ckpt_path = tf.train.latest_checkpoint(ckpt_dir)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AelEQkz8nbFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup helper functions for encoding and decoding\n",
        "def encode(input_str, output_str=None):\n",
        "  \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id \n",
        "  batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
        "  return {\"inputs\": batch_inputs}\n",
        "\n",
        "def decode(integers):\n",
        "  \"\"\"List of ints to str\"\"\"\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return encoders[\"inputs\"].decode(np.squeeze(integers)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYe9HYCxoSrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hparams and the model\n",
        "model_name = \"transformer\"\n",
        "hparams_set = \"transformer_tpu\"\n",
        "\n",
        "# Other setup\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "hparams = trainer_lib.create_hparams(hparams_set, data_dir=data_dir, problem_name=\"translate_en_tr\")\n",
        "\n",
        "# NOTE: Only create the model once when restoring from a checkpoint; it's a\n",
        "# Layer and so subsequent instantiations will have different variable scopes\n",
        "# that will not match the checkpoint.\n",
        "translate_model = registry.model(model_name)(hparams, Modes.EVAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h07TC7gLoceR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Restore and translate!\n",
        "def translate(inputs, beam_size = 5, alpha = 0.6, **kwargs):\n",
        "  encoded_inputs = encode(inputs)\n",
        "  with tfe.restore_variables_on_create(ckpt_path):\n",
        "    model_output = translate_model.infer(encoded_inputs, **kwargs)[\"outputs\"]\n",
        "  if len(model_output.shape) == 2:\n",
        "    return decode(model_output)\n",
        "  else:\n",
        "    return [decode(x) for x in model_output[0]]\n",
        "  \n",
        "def translate_and_display(input):\n",
        "  output = translate(input)\n",
        "  print('\\n  '.join(textwrap.wrap(\"Input: {}\".format(input), 80)))\n",
        "  print()\n",
        "  print('\\n  '.join(textwrap.wrap(\"Output: {}\".format(output), 80)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSfMzXUDRonD",
        "colab_type": "text"
      },
      "source": [
        "## Translation Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6CcLZ7vRbFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "67bcb804-1598-4d6d-9a53-68ae2e9effac"
      },
      "source": [
        "inputs = \"If Turkey provides a competitive, safe, and predictable business and \\\n",
        "investment environment, it can reach high growth rates and development levels, \\\n",
        "with its alternative tourism opportunities, agriculture, young, educated \\\n",
        "population, and entrepreneurial spirit.\"\n",
        "\n",
        "translate_and_display(inputs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: If Turkey provides a competitive, safe, and predictable business and\n",
            "  investment environment, it can reach high growth rates and development levels,\n",
            "  with its alternative tourism opportunities, agriculture, young, educated\n",
            "  population, and entrepreneurial spirit.\n",
            "\n",
            "Output: Türkiye rekabetçi, güvenli ve öngörülebilir bir iş ve yatırım ortamı\n",
            "  sağladığı takdirde, alternatif turizm fırsatları, tarım, genç, eğitimli genç ve\n",
            "  girişimcilik ruhuyla yüksek büyüme oranları ve kalkınma seviyelerine ulaşabilir.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhuledyxOCqU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkyVCcmOET9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "189fdf7b-fd34-41a8-f46d-84c5c2876ba1"
      },
      "source": [
        "inputs = \"The businessman Arron Banks and the unofficial Brexit campaign Leave.EU have \\\n",
        "issued a legal threat against streaming giant Netflix in relation to The Great Hack, \\\n",
        "a new documentary about the Cambridge Analytica scandal and the abuse of personal data.\"\n",
        "\n",
        "translate_and_display(inputs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: The businessman Arron Banks and the unofficial Brexit campaign Leave.EU\n",
            "  have issued a legal threat against streaming giant Netflix in relation to The\n",
            "  Great Hack, a new documentary about the Cambridge Analytica scandal and the\n",
            "  abuse of personal data.\n",
            "\n",
            "Output: İşadamı Arron Banks ve gayrı resmi Brexit kampanyası devam ediyor. AB,\n",
            "  Analytica skandalı ve kişisel verilerin kötüye kullanımıyla ilgili yeni bir\n",
            "  belgesel olan Büyük Hack ile ilgili olarak sokak devir Netflix'i kaldırmaya\n",
            "  yönelik yasal tehdit yayınladı.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ4hdjYxPXv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "86ca6dad-7890-492d-b0cc-e44fef2d22bd"
      },
      "source": [
        "inputs = \"The threat comes as press freedom campaigners and charity groups warn \\\n",
        "the government in an open letter that UK courts are being used to “intimidate \\\n",
        "and silence” journalists working in the public interest.\"\n",
        "\n",
        "translate_and_display(inputs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: The threat comes as press freedom campaigners and charity groups warn the\n",
            "  government in an open letter that UK courts are being used to “intimidate and\n",
            "  silence” journalists working in the public interest.\n",
            "\n",
            "Output: Söz konusu tehdit, basın özgürlüğü kampanyacıları ve yardım örgütlerinin\n",
            "  hükümeti, İngiliz mahkemelerinin, kamu yararına çalışan gazetecileri \"sindirmeye\n",
            "  ve susturmaya\" alıştığı açık bir mektupta uyarmaları üzerine geldi.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y8ntUNeO7Ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d4622354-7f05-4a2b-de43-f68915bbabc3"
      },
      "source": [
        "inputs = \"Alexandria Ocasio-Cortez called for a “9/11-style commission” to \\\n",
        "investigate child separation on the border with Mexico on Saturday, and said \\\n",
        "the US government has a life-long responsibility to children it severed from \\\n",
        "their parents, to provide them with mental health support.\"\n",
        "\n",
        "\n",
        "translate_and_display(inputs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Alexandria Ocasio-Cortez called for a “9/11-style commission” to\n",
            "  investigate child separation on the border with Mexico on Saturday, and said the\n",
            "  US government has a life-long responsibility to children it severed from their\n",
            "  parents, to provide them with mental health support.\n",
            "\n",
            "Output: Alexandria Ocasio-Cortez Cumartesi günü Meksika sınırındaki çocuk\n",
            "  ayrımını araştırması için \"9/11 tarzı bir komisyon\" çağrısında bulundu ve ABD\n",
            "  hükümetinin ailelerinden gelen çocuklara olan sağlığına yönelik ömür boyu bir\n",
            "  sorumluluk taşıdığını söyledi.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}